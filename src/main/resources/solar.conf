# *************************Spark config
solar.spark.app.name = SOLAR
solar.spark.stream.batchDuration = 1000
solar.spark.driver.cores = 4
solar.spark.driver.maxResultSize = 2g
solar.spark.driver.memory = 1g
solar.spark.task.maxFailures = 1
solar.spark.stream.checkpoint = ./solar
# solar.spark.yarn.am.memory=1g
# solar.spark.driver.memory=1g
# solar.spark.driver.cores=2
# solar.spark.yarn.am.cores=1
# solar.spark.yarn.am.waitTime=100s
# solar.spark.yarn.max.executor.failures=
# solar.spark.executor.cores=1
# solar.spark.executor.instances=2
# solar.spark.yarn.jars=
# solar.spark.jars=
# solar.spark.task.maxFailures=-1
# solar.spark.driver.host=
# solar.spark.driver.port=
solar.spark.executor.memory=2g
solar.spark.executor.cup=4
# solar.spark.rdd.compress=
# solar.spark.streaming.kafka.maxRetries=1
# solar.spark.streaming.kafka.maxRetries=200
# solar.spark.streaming.stopGracefullyOnShutdown=ture

solar.kafka.bootstrap.servers = sunb:9092,suna:9092,sunc:9092
solar.kafka.topics = test1,test2,test3,test4,test4,test5,test6,test7,test8,test9,test10
solar.kafka.key.deserializer = org.apache.kafka.common.serialization.ByteArraySerializer
solar.kafka.value.deserializer = org.apache.kafka.common.serialization.ByteArraySerializer
solar.kafka.group.id = solar
#solar.kakfa.auto.offset.reset = latest
solar.kafka.enable.auto.commit = ture


# Merge
merge.illegal.topics =
merge.normal.topics=
merge.kafka.bootstrap.servers =
merge.kafka.value.serializer = org.apache.kafka.common.serialization.ByteArraySerializer
merge.kafka.key.serializer = org.apache.kafka.common.serialization.ByteArraySerializer
#merge.kafka.acks=all
#merge.kafka.retries=2
#merge.kafka.batch.size=0
#merge.kafka.linger.ms=1
#merge.kafka.partitioner.class= com.wuzhou.producer.PartitionRouter
# merge.kafka.buffer.memory=
# merge.kafka.client.id=
# merge.kafka.compression.type=
# merge.kafka.connections.max.idle.ms=

# merge.kafka.max.block.ms=
# merge.kafka.max.in.flight.requests.per.connection=
# merge.kafka.max.request.size=
# merge.kafka.metadata.max.age.ms=
# merge.kafka.metric.reporters=
# merge.kafka.metrics.num.samples=
# merge.kafka.metrics.sample.window.ms=

# merge.kafka.receive.buffer.bytes=
# merge.kafka.reconnect.backoff.ms=
# merge.kafka.request.timeout.ms=
# merge.kafka.retry.backoff.ms=
# merge.kafka.send.buffer.bytes=



merge.hbase.table.baseinfo = BASEINFO
merge.hbase.table.image = IMAGE

merge.hbase.hbase.zookeeper.quorum = mercury,staturn,venus
merge.hbase.hbase.zookeeper.property.clientPort = 2181
merge.hbase.hbase.client.write.buffer = 12582912
merge.hbase.hbase.client.max.total.tasks = 500
merge.hbase.hbase.client.max.perserver.tasks = 5
merge.hbase.hbase.client.max.perregion.tasks = 1



# *********************ES config
merge.es.cluster.name=myApp
merge.es.addrees=suna:9300,sunb:9300,sunc:9300
merge.es.index=traffic
merge.es.type=vehicle
#merge.es.resource = ""
#merge.es.resource.write =""
# merge.es.host =
# merge.es.port =
# *********************Mysql config
merge.mysql.driver = com.mysql.jdbc.Driver
merge.mysql.user =
merge.mysql.host = jdbc:mysql://
merge.mysql.password =
